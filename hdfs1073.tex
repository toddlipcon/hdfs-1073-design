\documentclass{article}
\pdfpagewidth 8.5in
\pdfpageheight 11in 

\setlength\topmargin{0in}
\setlength\headheight{0in}
\setlength\headsep{0in}
\setlength\textheight{7.7in}
\setlength\textwidth{6.5in}
\setlength\oddsidemargin{0in}
\setlength\evensidemargin{0in}
\setlength\parindent{0.25in}
\title{HDFS-1073 Design Document}
\author{Todd Lipcon\\todd@cloudera.com}
\begin{document}
\maketitle
\tableofcontents

\section{Transaction IDs}

HDFS has had the concept of a transaction ID used inside {\tt FSEditLog} for a long time.
Transaction IDs are assigned sequentially to threads as they write data into the log. They
are then used to facilitate group commit during {\tt logSync()}.

\subsection{Persistent Transaction IDs}

One of the subtasks of HDFS-1073 is HDFS-1521, which makes the transaction IDs persist
across restarts of the NameNode. That is to say, the first edit on a newly formatted
NN will have transaction ID 1, and that ID will never be reused for the lifetime of
the namesystem (even after restarts and checkpoints).

\subsection{Non-namespace transactions}

{\tt FSEditLog} already contains a couple of {\em special} transactions which do not correspond
to actual modifications of the filesystem namespace, but instead are used to inform the
BackupNode when the primary NameNode's logs are rolled, etc. We plan to add the following
special transactions:

\begin{enumerate}
\item {\tt OP\_BEGIN\_LOG\_SEGMENT} - this transaction is written at the start of every new
edit log file. It currently contains no data, but may later contain some special checkpointing
information or metadata about the namespace.
\item {\tt OP\_END\_LOG\_SEGMENT} - this transaction is written at the end of an edit log
before it is closed. This is used as a sanity check that the log was gracefully closed, and
is also useful to allow the BackupNode to synchronize its log roll with the primary NameNode.
In the future it might be extended to include some kind of checksum information about the log
file.
\end{enumerate}

These two special transactions also serve another purpose: they ensure that all edit logs
contain at least one transaction. This avoids having to add many special case code-paths
for empty edits files.

\section{Storage contents}

The NN storage directories continue to be organized in the same way - either edits, images, or both.
The difference is that each edits or {\tt fsimage} file now has a suffix indicating the transaction IDs
contained in the file.

Files within a storage directory will have a name matching one of the following patterns:

\begin{itemize}
\item {\tt fsimage\_N} - this is a namesystem checkpoint that reflects all transactions
up to and including transaction ID $N$.
\item {\tt edits\_inprogress\_N} - this is an edit log whose first transaction has transaction
ID $N$ and whose last transaction ID is unknown. This is the case for the log that is currently
being written to by an active NameNode, or a previous NameNode that was shutdown uncleanly.
\item {\tt edits\_N-M} - this is an edit log whose first transaction is $N$ and whose last
transaction is $M$. It contains all transactions with identifier between $N$ and $M$ inclusive.
\end{itemize}

For example, a newly formatted NN has the following contents:

\begin{enumerate}
\item {\tt fsimage\_0} - empty image
\item {\tt edits\_inprogress\_1} - the edit log currently being appended
\end{enumerate}

When edits are rolled, the current {\tt edits\_inprogress} file is ``finalized'' by renaming to {\tt edits\_N-M}.
So, if we roll the edits of the above image after making 10 edits, we end up with:

\begin{enumerate}
\item {\tt fsimage\_0} - same empty image
\item {\tt edits\_1-10} - any edits made before the roll
\item {\tt edits\_inprogress\_11} - the edit log currently being appended
\end{enumerate}

When an image is saved or uploaded via a checkpoint, the validity rule is as follows:
any {\tt fsimage} with txid $N$ must incorporate all edits from logs containing earlier transaction IDs.
So, if we enter safe mode and call {\tt saveNamespace} on the above example, we end up with:
\begin{enumerate}
\item  {\tt fsimage\_0} - original empty imagge
\item  {\tt edits\_1-10} - edits before first roll
\item  {\tt edits\_11-12} - edit log containing special {\tt BEGIN\_LOG\_SEGMENT} and {\tt END\_LOG\_SEGMENT} transactions but no actual namespace changes.
\item  {\tt fsimage\_12} - all edits from both edit logs have bee incorporated into namespace
\item  {\tt edits\_inprogress\_13} - the edit log where new edits will be appended
\end{enumerate}

\section{Log Rolling}

\subsection{Triggers to roll logs}
The following events can trigger a log roll:

\begin{enumerate}
\item NN startup (see below)
\item {\tt saveNamespace}
\item a secondary or backup node wants to begin a checkpoint
\item a storage directory that had previously failed becomes available
\item potentially we may find it useful to expose this as an admin function? (eg mysql offers a {\tt FLUSH LOGS} command, useful for backups)
\end{enumerate}

\subsection{Log rolling process}

\begin{enumerate}
\item The current {\tt edits\_inprogress\_N} log is closed
\item The current {\tt edits\_inprogress\_N} log is renamed to {\tt edits\_N-M} in all valid edits directories.
\item Any edits directories that previously had problems will be left with {\tt edits\_inprogress\_N} (since we don't know whether all of the edits made it into that log before the roll -- in fact they probably did not)
\item The next {\tt edits\_inprogress\_M+1} is opened in all directories, including an attempt to reopen any failed directories.
\end{enumerate}

\section{Startup behavior}

\subsection{Log recovery (primary NN)}\label{logrecovery}
First we initiate log recovery:
\begin{enumerate}
  \item Across all edits directories, look for any {\tt edits\_inprogress\_N}.
  \item For each N for which we located {\tt edits\_inprogress\_N}:
  \begin{enumerate}
    \item Look for any finalized edits file starting with the same transaction ID $N$ in any other log directory
    \item If there is at least one finalized {\tt edits\_N-M,} then the {\tt edits\_inprogress\_N} is likely corrupt â€“ rename it to {\tt edits\_inprogress\_N\_corrupt} (or delete it if we are less cautious)
    \item If there are no finalized {\tt edits\_N-M} files, then the NN crashed while we were writing log index N. Initiate recovery process across all {\tt edits\_N\_inprogress}
    \begin{enumerate}
      \item  For each log, calculate the ``valid length'' of the file - ie the length of the file after subtracting any trailing {\tt \\x00 bytes}
      \item  After we've determined the longest log, use that one when replaying logs.
    \end{enumerate}
  \end{enumerate}
\end{enumerate}

\subsection{Log recovery (backup node)}\label{bnrecovery}

On the backup node, any {\tt inprogress} edits files must be removed, and later refetched from the primary NN.
These files are most likely truncated, since they indicate that the BN crashed while replicating the file, and the
primary NN may have flushed more edits since then.

\subsection{Image recovery}

Any {\tt fsimage\_ckpt\_N} that exists is likely to be incomplete, as the {\tt \_ckpt} suffix indicates that the image is in progress of being written. Thus, we remove any of these images (or mark as .corrupt if we are feeling cautious)

\subsection{Namespace reconstruction}
\label{ns-reconstruction}
After performing the above recovery actions, we must determine which files to load in order to reconstruct the namespace.

\begin{enumerate}
\item Find the {\tt fsimage\_N} with the highest N across all image directories.
\item Then, find all log files that start with a txid greater than $N$.
\item Group all log files by their starting txid.
\item {\bf Invariant:} all log files that start with the same txid should end with the same txid.
\item {\bf Invariant:} if there is a log group for txid $N$ through $M$, then that is either the last log group, or the next group starts at txid $M+1$.
\end{enumerate}

We then start up the NN by the following sequence:
\begin{enumerate}
\item load {\tt fsimage\_N}
\item Load any log from log group starting at $N+1$ (which ends at $M$)
\item Load any log from log group starting at $M+1$
\item ...etc...
\item open {\tt edits\_inprogress\_Q} where Q is one transaction higher than the ending transaction of the last log group.
\end{enumerate}

\subsection{Upgrade}

Upgrade processes are essentially unmodified, except that we must be sure that we can read the old layout ({\tt fsimage}, {\tt edits}, and {\tt edits.new}) in order to perform an upgrade. The changes described in this document change the layout only within the {\tt current/} directory and thus the management of {\tt previous} during upgrade rollback and finalization is unaffected.

{\bf Open question:} do we need to support upgrade from a namespace that was not cleanly shut down?

\section{saveNamespace process}

The process for the primary NN to save its own namespace is:

\begin{enumerate}
\item NN must be in safe mode (this quiesces any incoming edits to the namesystem)
\item NN ends the currently open in-progress log segment by writing {\tt OP\_END\_SEGMENT} and renaming the file to finalize it.
Let $N$ be the transaction ID for the {\tt OP\_END\_SEGMENT} transaction.
\item NN saves its namespace into {\tt fsimage\_ckpt\_N} in each edit directory.
\item NN renames {\tt fsimage\_ckpt\_N} to {\tt fsimage\_N} in all edit directories.
\item NN opens {\tt edits\_inprogress\_N+1} in all log directories and writes {\tt OP\_BEGIN\_SEGMENT}.
\end{enumerate}

\subsection{Failure analysis}

\begin{itemize}
\item If the NN crashes after ending the prior segment but before saving the namespace,
the old edit log is finalized but the new log has not been created.
Log recovery proceeds as in section \ref{logrecovery} on restart.
\item If the NN crashes while saving its namespace, image recovery will remove the incomplete {\tt ckpt} image, and recovery is the same as above.
\item If the NN crashes after it has renamed one more of the new images, it will recover from that image and correctly ignore the {\tt edits} files with lower transaction IDs.
\end{itemize}

\section{Checkpoint process}
\label{2nn-checkpoint}
\begin{enumerate}
\item {\tt CheckpointSignature} is modified to include the transaction ID associated with the latest {\tt fsimage} file as well as the starting transaction ID of the currently in-progress edit log.
\item Checkpointing node issues {\tt beginCheckpoint} RPC to NN.
\item NN rolls edit logs, and returns a checkpoint signature as defined above.
\item Secondary NameNode issues an RPC {\tt getRemoteEditLogs} to fetch the list of finalized log segments in between the image transaction ID and the current log segment's transaction ID.
\item Image transfer servlet is augmented to allow the downloader to specify which image or edits file to download.
\item Checkpointer downloads {\tt fsimage\_N} and and all edits files containing transactions between $N$ and the transaction ID specified in the checkpoint signature.
  \begin{itemize}
  \item When each file is downloaded, it is initially written to {\tt edits\_inprogress\_N-M} or {\tt fsimage\_ckpt\_N} until it is verified. Once it is verified it can be renamed to the final destination {\tt edits\_N} or {\tt fsimage\_N}.
  \end{itemize}
 
\item Checkpointer saves local {\tt fsimage\_M}, and uploads to NN
  \begin{itemize}
  \item Similar to above, when the NN receives a new fsimage, it initially saves it as {\tt fsimage\_ckpt\_N} until the upload is complete. This prevents an aborted checkpoint from causing a corrupt storage directory.
  \end{itemize}
\item NN validation of the checkpoint signature is much simpler - just needs to make sure it came from the same filesystem, check any security tokens, etc. The old fstime and editstime constructs are no longer necessary since it's all encapsulated in the transaction IDs. For extra safety we can use the MD5 functionality from HDFS-903 as well.
\item NN saves {\tt fsimage\_M+1} into its local image dirs, but does not need to do any log manipulation.
\end{enumerate}

\subsection{Handling multiple secondary name nodes}

Note that in the above process there is no state stored on the NN with regard to ongoing checkpoint processes. If multiple checkpoint nodes checkpoint simultaneously, the NN will simply roll twice and hand a different checkpoint transaction ID to each. Each will then upload fsimages with different associated txids.


\section{BackupNode operation}

The BackupNode operation is substantially simplified by this new design. 

\subsection{BackupNode state}

The BN maintains the following pieces of state:

\begin{itemize}
\item {\tt journalState} - an enum, either {\tt IN\_SYNC} or {\tt JOURNAL}.
  \begin{itemize}
  \item {\tt IN\_SYNC} specifies that the BN's namespace is currently up to date with the primary NN, and any edits received should be immediately applied to the namespace, in addition to being logged to disk.
  \item {\tt JOURNAL} specifies that the BN's namespace is currently behind the primary NN, and edits should only be written to disk.
  \end{itemize}
\item {\tt namesystemReflectsLogsThroughTxId} - the index of the txid for which the BN has applied edits.
\item {\tt stopApplyingAtNextRoll} - a boolean allowing the checkpoint code to pause application of edit records (see section \ref{stopApplyingAtNextRoll})
\end{itemize}

\subsection{BackupNode Startup}

On startup, the BackupNode first performs storage recovery as described in section \ref{bnrecovery}.
It will then proceed with namespace reconstruction (see section \ref{ns-reconstruction}) in the same manner as if it were a primary NN.

When startup is complete, The {\tt namesystemReflectsLogsThroughTxId} variable will be up to date with the txid of the latest log or image that the BN has recovered.

The BN then registers itself with the primary NN, which begins sending it edits. Upon registration, the NN rolls its edit log and begins streaming edits to the BN starting with the new log.

The BN starts out in {\tt JOURNAL} mode, since it is not up to date with the current NN. In order to attain synchronization after startup, it may call {\tt catchupSynchronization} (see section \ref{catchupSynchronization}).

\subsection{Receiving edits}

Once registered, the NN streams all edits to the BN via RPC as in the existing design.

\subsubsection{Special edit records}


The {\tt OP\_BEGIN\_LOG\_SEGMENT} and {\tt OP\_END\_LOG\_SEGMENT} transactions are picked up by the BackupNode just like any other
transaction, and cause it to roll its local edit logs to stay in sync with the primary NameNode.

If {\tt stopApplyingAtNextRoll} is set, and the BN receives {\tt OP\_END\_LOG\_SEGMENT}, then the BN will transition from {\tt IN\_SYNC} into
{\tt JOURNAL} mode. That is to say, from that transaction on, edits will only be logged and not applied to the namespace.

\subsubsection{Applying and journaling edits}

Depending on the current {\tt journalState}, the BN takes different actions for each edit.

\begin{itemize}
\item If the state is {\tt IN\_SYNC} then the edit is immediately applied to the namesystem, and also written to disk.
\item If the state is {\tt JOURNAL} then the edit is only written to disk.
\end{itemize}

\subsection{Checkpointing}

In order to make a checkpoint, the BN takes the following steps:

\begin{enumerate}
\item Set {\tt stopApplyingAtNextRoll} flag.
\item Ask NN to {\tt beginCheckpoint}, which rolls logs - this triggers {\tt OP\_END\_LOG\_SEGMENT} which pushes us to {\tt JOURNAL} state.
\item We assert that BN's logs are now closed and we are in {\tt JOURNAL} state. As in section \ref{2nn-checkpoint} we receive a CheckpointSignature as a response to {\tt beginCheckpoint}.
\item If BN was previously {\tt IN\_SYNC} then we should already be up to date with the NN. If BN was not {\tt IN\_SYNC} then we download and apply edit logs between {\tt namesystemReflectsLogsThroughTxId} and the transaction ID referenced by the {\tt CheckpointSignature}.
\item Checkpoint image is uploaded as in section \ref{2nn-checkpoint}.
\item {\tt catchupSynchronization} is called (see section \ref{catchupSynchronization}).
\end{enumerate}

\subsection{Converging logs (TODO need to update this design for txid)}

After a checkpoint, we are in the {\tt JOURNAL} state and need to ``catch back up'' to the primary NN. The algorithm to do so is in pseudocode:
\label{catchupSynchronization}
\begin{verbatim}
def catchupSynchronization():
  assert we are in JOURNAL state
  converged = false
  while namesystemReflectsLogsThrough <= currentReceivingLog:
    if namesystemReflectsLogsThrough < currentReceivingLog:
      # we're still catching up on finalized logs
      fetchAndReplayLogIndex(namesystemReflectsLogsThrough + 1)
    else:
      converged = tryConverge(namesystemReflectsLogsThrough + 1)
  assert mode == IN_SYNC

def tryConverge(N):
  open current edits_N_inprogress that is being written to
  if the open fails due to FNFE:
    assert that edits_N exists [ie it got rolled before we opened it]
    return False

  replay logs until EOF
  lock journal
  if currentReceivingLog > N:
    # we rolled while replaying, go back to catchup sequence
    unlock journal
    assert that edits_N exists (ie that our open file got finalized under us)
    continue to replay logs from same open stream until EOF
    namesystemReflectsLogsThrough = N
    return False [we did not succeed in converging]

  assert currentReceivingLog == N
  replay last logs in edits_N_inprogress until another EOF
  set state = IN_SYNC
  namesystemReflectsLogsThrough = N
  unlock journal
  return True
\end{verbatim}

\subsection{Handling multiple BNs}

In the above design, the BN never assumes that the NN will be stop rolling for any period of time. All checkpoint operations are stateless with respect to the server. If multiple BNs start checkpoints separately, they will checkpoint at different transaction IDs, and upload fsimage files with different txids as well.

\section{Image/edits file retention policies}

There are a number of policies that should be simple to implement:
\begin{enumerate}
\item {\bf Number of saved images} - ensure that we have at least N saved images in our image directories, can delete any that are more than N versions old. Maintain edit lots that have starting txid $>=$ the txid of the Nth oldest image.
\item {\bf Time} - ensure that we maintain all images within a trailing time window - again maintain all edit logs with txids $>=$ the txid of the oldest maintained image.
\item {\bf Archival} - for audit purposes, the deletion mechanism could very easily be augmented to archive the edit logs for later analysis (eg to HDFS, tape, SAN, etc)
\end{enumerate}

\section{Future Directions}

Although we do not plan to implement the following ideas within the scope of this issue, we want to be confident that the design does not preclude implementation in the future. Here are brief sketches for some suggested future directions:

\subsection{NN-triggered checkpointing}

Rather than having the BN trigger checkpoints on a periodic basis, it would be very simple to modify the design so that the BN triggers checkpoints based on a special flag on {\tt OP\_END\_LOG\_SEGMENT}.

\subsection{Offline Checkpointing}

Rather than having a special daemon to perform checkpointing, it may be nice to have an offline tool that, given a storage directory, can perform a checkpoint for that directory.

This can be done as follows:
\begin{enumerate}
\item Read the {\tt fsimage\_N} with the highest N
\item Read any finalized {\tt edits} files containing txids higher than N.
\item Save {\tt fsimage\_M} into the same directory.
\end{enumerate}

Note that this will not checkpoint the current {\tt edits\_inprogress} if an NN is currently running in this directory. If we want an uptodate checkpoint, we can trigger the NN to roll - this is very simple, and could be done through a new {\tt dfsadmin -rollEdits} command.

In order to prevent collisions with other checkpointers, we need exclusive write access to the {\tt fsimage\_ckpt\_M} file while we write it. This is easy to achieve on most filesystems using advisory locking. Alternatively, checkpointers could checkpoint into uniquely named {\tt fsimage\_ckpt\_M\_<GUID>} files to avoid overlap, and then atomically rename the checkpoints into place when complete.

\subsection{Shared storage for metadata}

One of the primary advantages to the design in this document is that for any finalized edits or image file name, the contents of that file should be exactly identical across an entire cluster, including NNs, 2NNs, or BNs. In the current design, the primary and backup nodes communicate only by transfering complete files back and forth. For example, {\tt edits\_1000-2000} on the NN is fetched into the same name {\tt edits\_1000-2000} on the BN or 2NN.

  To switch to a shared storage directory, the {\tt TransferFsImage} calls would essentially be replaced by no-ops. The BN would be modified to tail the current {\tt edits\_inprogress} file from the shared edits directory. When the BN encounters the {\tt OP\_END\_LOG\_SEGMENT} record, it simply opens the next log file in sequence to continue tailing edits.

This is similar to the current design of the AvatarNode, except that it requires no coordination between checkpoints and the avatar.

\section{Test Plan}

\subsection{Existing Unit Tests}

The following unit tests already exist and will be modified to respect the new storage layout:
\begin{itemize}
\item {\tt TestBackupNode}
\item {\tt TestCheckpoint}
\item {\tt TestEditLog}
\item {\tt TestEditLogRace}
\item {\tt TestNameEditsConfigs}
\item {\tt TestSaveNamespace}
\item {\tt TestSecurityTokenEditLog}
\item {\tt TestStartup}
\item {\tt TestStorageRestore}
\end{itemize}

These unit tests cover the majority of basic functionality of this feature, as well as regression tests for bugs found in the old implementation.

Some unit tests will have additional test cases.

\subsubsection{TestCheckpoint}

A new test case will be added to show that multiple checkpoints can be taken from multiple CNs with no interference.

\subsubsection{TestBackupNode}

A new test case will be added to show that multiple BackupNodes can run at the same time against the same NN with no interference.

\subsection{New Unit Tests}

\subsubsection{TestEditLogRecovery}

The first case ensures that the NN will recover from edit logs that are found spread across several directories.

\begin{enumerate}
\item Create a NameNode with 3 storage directories
\item Alternate between making some edits and rolling logs, such that each storage directory contains {\tt edits\_0} through {\tt edits\_10}
\item Stop the NN
\item In each directory, delete a non-overlapping set of edit logs, such that the first directory contains {\tt edits\_0}, {\tt edits\_3}, etc.\ and the second directory contains {\tt edits\_1}, {\tt edits\_4}, etc.
\item Start the NN and verify that all edits have been restored.
\item Verify that a new image file has been saved with the correct index.
\end{enumerate}

The second test ensures that the NN will properly discard {\tt edits\_N\_inprogress} files:

\begin{enumerate}
\item Create a NameNode with 3 storage directories
\item Alternate between making some edits and rolling logs, such that each storage directory contains {\tt edits\_0} through {\tt edits\_10}
\item Stop the NN
\item In each directory, corrupt a non-overlapping set of edit files by renaming them to have the {\tt \_inprogress} suffix and then overwriting them with random data.
\item Start the NN and verify that all edits have been restored, and the corrupted files have been renamed to {\tt edits\_N\_corrupt}
\item Verify that a new image file has been saved with the correct index.
\end{enumerate}

The third test ensures that if the last edits file is in progress, it will be finalized at startup.

\begin{enumerate}
\item Create a NameNode with 3 storage directories
\item Alternate between making some edits and rolling logs, such that each storage directory contains {\tt edits\_0} through {\tt edits\_10}
\item Assert that the last edit file is named with an {\tt \_inprogress} suffix.
\item Start the NN and verify that all edits have been restored, and that the last log was finalized.
\item Verify that a new image file has been saved with the correct index.
\end{enumerate}

\subsection{BackupNode Stress Test}

This is a stress test that can be implemented in a JUnit fixture and either run as part of the unit tests or run manually.

\begin{enumerate}
\item Start a NN and two BNs connected to it, each configured to make checkpoints several times per second.
\item In several threads, make edits to the NN as fast as possible
\item Let the system run for as many minutes as desired. While it is running, the following faults can be injected:
  \begin{enumerate}
  \item A storage directory becomes temporarily inaccessible on either the NN or a BN (eg manually chmod 000)
  \item A BN crashes and restarts
  \item The network between the NN and BN fails.
  \end{enumerate}
\item Stop system
\item Verify across all storage directories the following invariant: if there exists a file with name $f$, and the file does not have an {\tt \_inprogress} or {\tt \_ckpt} suffix, then it must have an identical SHA1 checksum to all other files with the same name across all nodes.
\end{enumerate}




\end{document}
